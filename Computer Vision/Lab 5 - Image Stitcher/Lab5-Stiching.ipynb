{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Image Stitching for Panorams\n",
    "\n",
    "### What to Submit\n",
    "Submit this iPython Notebook--containing all your code for the programming exercises below--on Canvas.\n",
    "\n",
    "### Programming Exercise\n",
    "\n",
    "For this assignment, you will be writing a program that creates an image panorama from 2 or more images.  In general this technique should be applicable to any number of photographs.  The approach described below will work well for collective fields of up to 90 or even 120&deg;, but won't produce ideal results for large fields of view approaching or surpassing 180&deg;.  For large fields of view, cylindrical or spherical projection is required.\n",
    "\n",
    "When we construct a panorama, we assume that all of the photographs were taken from the exact same location and that the images are related by pure rotation (no translation of the camera).  The easiest way to create the panorama is to project all of the photos onto a plane.  One photo must be selected (either manually or by your program) to be the base photo.  The other photos are aligned to this base photo by identifying a homography (a planar warp specified by 4 pairs of source/destination points) relating each pair.  Each of the other images is appropriately warped and composited onto the plane (the base image doesn’t need to be warped).\n",
    "\n",
    "In describing what you need to do, there will be a running example using the three photos below:\n",
    "\n",
    "\n",
    "<div style=\"width:100%;text-align:center;\"><img src=\"Images/example1.png\" width=100%></div>\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Find Interest Points/Descriptors in each Input Image\n",
    "We will be using OpenCV for this project, which you should already have installed. Although the SIFT algorithm is patented and used to require a separate install, it is now included in the newer versions of OpenCV. A good tutorial on how to use SIFT features in OpenCV is found [here](https://docs.opencv.org/trunk/da/df5/tutorial_py_sift_intro.html).  The first step to registering or aligning two images is to identify locations in each image that are distinctive or stand out.  The `sift.detectAndCompute()` routine produces both these interest points and their corresponding SIFT descriptors.  The first step of producing a panorama is to load all of the relevant images and find the interest points and their descriptors.\n",
    "\n",
    "See the circles on each image below indicating the sift keypoints that were found (note that we downsampled the images to 600 x 600 pixels before extracting SIFT). The circles are scaled according to the scale at which each keypoint was detected at and the radius indicates the dominate gradient magnitude. Output a similar visual in your code.\n",
    "\n",
    "<div style=\"width:100%;text-align:center;\"><img src=\"Images/example2.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Matching Features\n",
    "\n",
    "Next, given the features present in each image, you need to match the features so as to determine corresponding points between adjacent/overlapping images.  [This page](https://docs.opencv.org/trunk/dc/dc3/tutorial_py_matcher.html) provides details to do feature matching using `cv2.BFMatcher()`, analogous to the approach proposed by David Lowe in his original implementation.  Be aware that the resulting match is one directional.  You want to find putative pairs--pairs of points which are each other’s best match (e.g. there might be 3 points in image I1 for which a point q in image I2 are the best match, only one of these could be the best matching point p in I1 for that point q in I2).  In this part you need to compute the set of putative matches between each pair of images.\n",
    "\n",
    "Look at the pairs of images and the lines showing the estimated matches (putative matches are green lines, one way matches are cyan or blue). Output a similar visual in your code (the images can be side by side, it doesn't have to be vertical).\n",
    "\n",
    "<div style=\"width:100%;text-align:center;\"><img src=\"Images/example3.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Estimating Pairwise Homographies using RANSAC\n",
    "\n",
    "Use the RANSAC algorithm ([Szeliski](http://szeliski.org/Book/), Ch 8.1.4), estimate the homography between each pair of images.  You will need to decide whether you’re going to manually specify the base image or determine in programmatically.  Along with identifying the base image, you need to figure out the order in which you will composite the other images to the base.\n",
    "\n",
    "You will need 4 pairs of best-match points to estimate a homography for each composited image. Below you will find a visualization of the RANSAC estimated homographies.  Images 1, 2, and 3 have dots that are red, green and blue respectively (sorry the dots are a little small), representing the putative pairs.  You can see where the homographies line up very well and in a few places (the middle vertically) they line up slightly less well.\n",
    "\n",
    "For this section, you may use `cv2.findHomography()` or use the code from Lab 4 to generate the homography matrix. However, you must implement RANSAC yourself. Additionally, you may simply take the best homography of those randomly sampled, but as a possible improvement, you may implement a least squares optimization over the largest consesus set.\n",
    "\n",
    "<div style=\"width:100%;text-align:center;\"><img src=\"Images/example4.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D: Creating the Mosaic\n",
    "\n",
    "Begin with the base image and warp the remaining images (using the estimated homographies) to composite them onto the base image. You may use `cv2.warpPerspective()` for the backwards warping (Note: You may need to multiply your homography by a translation matrix keep it in the frame. You can then translate it back to put it on the correct part of the mosaic.).\n",
    "\n",
    "For the ongoing campus example, here are the resulting warped images composited.\n",
    "\n",
    "<div style=\"width:100%;text-align:center;\"><img src=\"Images/example5.png\" width=75%></div>\n",
    "\n",
    "And, then with a very simple (but not ideal) compositing operation using the median of the mapped pixels.\n",
    "\n",
    "<div style=\"width:100%;text-align:center;\"><img src=\"Images/example6.png\" width=75%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Find Interest Points/Descriptors (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Place Code Here\n",
    "# Show an example output here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Matching Features (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place Code Here\n",
    "# Show an example output here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Estimating Pairwise Homographies using RANSAC (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place Code Here\n",
    "# Show an example output here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D: Creating the Mosaic (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place Code Here\n",
    "# Show an example output here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
